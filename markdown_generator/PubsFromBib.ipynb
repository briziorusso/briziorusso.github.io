{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a set of bibtex of publications and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). \n",
    "\n",
    "The core python code is also in `pubsFromBibs.py`. \n",
    "Run either from the `markdown_generator` folder after replacing updating the publist dictionary with:\n",
    "* bib file names\n",
    "* specific venue keys based on your bib file preferences\n",
    "* any specific pre-text for specific files\n",
    "* Collection Name (future feature)\n",
    "\n",
    "TODO: Make this work with other databases of citations, \n",
    "TODO: Merge this with the existing TSV parsing solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybtex.database.input import bibtex\n",
    "import pybtex.database.input.bibtex \n",
    "from time import strptime\n",
    "import string\n",
    "import html\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_bibfile = 'all_pubs.bib'\n",
    "proceedings_file = 'proceedings.bib'\n",
    "journals_file = 'pubs.bib'\n",
    "\n",
    "# Initialize or clear the output files\n",
    "open(proceedings_file, 'w').close()\n",
    "open(journals_file, 'w').close()\n",
    "\n",
    "with open(main_bibfile, 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Split the content into individual BibTeX entries\n",
    "entries = content.split('@')\n",
    "# Remove any empty strings resulting from the split\n",
    "entries = [entry.strip() for entry in entries if entry.strip()]\n",
    "\n",
    "for entry in entries:\n",
    "    # Prepend '@' since it was removed during the split\n",
    "    entry = '@' + entry\n",
    "    # Identify the entry type (e.g., article, inproceedings)\n",
    "    entry_type = entry.split('{')[0].lower()\n",
    "    \n",
    "    if entry_type in ['@inproceedings', '@proceedings', '@conference']:\n",
    "        with open(proceedings_file, 'a', encoding='utf-8') as f1:\n",
    "            f1.write(entry + '\\n\\n')  # Add spacing between entries\n",
    "    elif entry_type in ['@article', '@book', '@misc', '@techreport']:\n",
    "        with open(journals_file, 'a', encoding='utf-8') as f2:\n",
    "            f2.write(entry + '\\n\\n')\n",
    "    else:\n",
    "        # Handle other types or skip\n",
    "        print(f\"Unknown entry type: {entry_type}\")\n",
    "\n",
    "publist = {\n",
    "    \"proceeding\": {\n",
    "        \"file\" : proceedings_file,\n",
    "        \"venuekey\": \"booktitle\",\n",
    "        \"venue-pretext\": \"In \",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "        \n",
    "    },\n",
    "    \"journal\":{\n",
    "        \"file\": journals_file,\n",
    "        \"venuekey\" : \"journal\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\",\n",
    "    '{\"{u}}' : \"&uuml;\",\n",
    "    \"{-}\" : \"-\",\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedCaseInsensitiveDict([('title', '{Shapley-PC: Constraint-based Causal Structure Learning with a Shapley Inspired Framework}'), ('booktitle', 'Proceedings of the 5th Conference on Causal Learning and Reasoning, {CLeaR} 2024, Lousanne, Switzerland. May 7-9, 2025 (Forthcoming)'), ('url', 'https://arxiv.org/abs/2312.11582'), ('year', '2025')])\n",
      "SUCESSFULLY PARSED russo2023shapley: \" {Shapley-PC: Constraint-based Causal Structure Learning with ... \"\n",
      "OrderedCaseInsensitiveDict([('title', 'Argumentative Causal Discovery'), ('booktitle', 'Proceedings of the 21st International Conference on Principles of Knowledge Representation and Reasoning, {KR} 2024, Hanoi, Vietnam. November 2-8, 2024'), ('year', '2024'), ('url', 'https://doi.org/10.24963/kr.2024/88'), ('doi', '10.24963/KR.2024/88'), ('timestamp', 'Wed, 18 Dec 2024 13:51:42 +0100'), ('biburl', 'https://dblp.org/rec/conf/kr/0002RT24.bib'), ('bibsource', 'dblp computer science bibliography, https://dblp.org')])\n",
      "SUCESSFULLY PARSED DBLP:conf/kr/0002RT24: \" Argumentative Causal Discovery  \"\n",
      "OrderedCaseInsensitiveDict([('title', 'Contestable {AI} Needs Computational Argumentation'), ('booktitle', 'Proceedings of the 21st International Conference on Principles of Knowledge Representation and Reasoning, {KR} 2024, Hanoi, Vietnam. November 2-8, 2024'), ('year', '2024'), ('url', 'https://doi.org/10.24963/kr.2024/83'), ('doi', '10.24963/KR.2024/83'), ('timestamp', 'Wed, 18 Dec 2024 00:00:00 +0100'), ('biburl', 'https://dblp.org/rec/conf/kr/LeofanteADFGJP024.bib'), ('bibsource', 'dblp computer science bibliography, https://dblp.org')])\n",
      "SUCESSFULLY PARSED DBLP:conf/kr/LeofanteADFGJP024: \" Contestable {AI} Needs Computational Argumentation  \"\n",
      "OrderedCaseInsensitiveDict([('title', 'Causal Discovery and Knowledge Injection for Contestable Neural Networks'), ('booktitle', \"{ECAI} 2023 - 26th European Conference on Artificial Intelligence, September 30 - October 4, 2023, Krak{\\\\'{o}}w, Poland - Including 12th Conference on Prestigious Applications of Intelligent Systems {(PAIS} 2023)\"), ('series', 'Frontiers in Artificial Intelligence and Applications'), ('volume', '372'), ('pages', '2025--2032'), ('publisher', '{IOS} Press'), ('year', '2023'), ('url', 'https://doi.org/10.3233/FAIA230495'), ('doi', '10.3233/FAIA230495'), ('timestamp', 'Wed, 15 Jan 2025 15:09:07 +0100'), ('biburl', 'https://dblp.org/rec/conf/ecai/0002T23.bib'), ('bibsource', 'dblp computer science bibliography, https://dblp.org')])\n",
      "SUCESSFULLY PARSED DBLP:conf/ecai/0002T23: \" Causal Discovery and Knowledge Injection for Contestable Neu ... \"\n",
      "OrderedCaseInsensitiveDict([('title', 'Argumentation for Interactive Causal Discovery'), ('booktitle', 'Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence, {IJCAI} 2023, 19th-25th August 2023, Macao, SAR, China'), ('pages', '7091--7092'), ('publisher', 'ijcai.org'), ('year', '2023'), ('url', 'https://doi.org/10.24963/ijcai.2023/820'), ('doi', '10.24963/IJCAI.2023/820'), ('timestamp', 'Tue, 15 Oct 2024 16:43:28 +0200'), ('biburl', 'https://dblp.org/rec/conf/ijcai/000223.bib'), ('bibsource', 'dblp computer science bibliography, https://dblp.org')])\n",
      "SUCESSFULLY PARSED DBLP:conf/ijcai/000223: \" Argumentation for Interactive Causal Discovery  \"\n",
      "OrderedCaseInsensitiveDict([('title', 'Forging Argumentative Explanations from Causal Models'), ('booktitle', 'Proceedings of the 5th Workshop on Advances in Argumentation in Artificial Intelligence 2021 co-located with the 20th International Conference of the Italian Association for Artificial Intelligence (AIxIA 2021), Milan, Italy, November 29th, 2021'), ('series', '{CEUR} Workshop Proceedings'), ('volume', '3086'), ('publisher', 'CEUR-WS.org'), ('year', '2021'), ('url', 'https://ceur-ws.org/Vol-3086/paper3.pdf'), ('timestamp', 'Mon, 24 Apr 2023 01:00:00 +0200'), ('biburl', 'https://dblp.org/rec/conf/aiia/0001RABT21.bib'), ('bibsource', 'dblp computer science bibliography, https://dblp.org')])\n",
      "SUCESSFULLY PARSED DBLP:conf/aiia/0001RABT21: \" Forging Argumentative Explanations from Causal Models  \"\n",
      "OrderedCaseInsensitiveDict([('title', 'Online Handbook of Argumentation for {AI:} Volume 4'), ('journal', 'CoRR'), ('volume', 'abs/2401.09444'), ('year', '2024'), ('url', 'https://doi.org/10.48550/arXiv.2401.09444'), ('doi', '10.48550/ARXIV.2401.09444'), ('eprinttype', 'arXiv'), ('eprint', '2401.09444'), ('timestamp', 'Mon, 05 Feb 2024 00:00:00 +0100'), ('biburl', 'https://dblp.org/rec/journals/corr/abs-2401-09444.bib'), ('bibsource', 'dblp computer science bibliography, https://dblp.org')])\n",
      "SUCESSFULLY PARSED DBLP:journals/corr/abs-2401-09444: \" Online Handbook of Argumentation for {AI:} Volume 4  \"\n",
      "OrderedCaseInsensitiveDict([('title', 'Contestable {AI} needs Computational Argumentation'), ('journal', 'CoRR'), ('volume', 'abs/2405.10729'), ('year', '2024'), ('url', 'https://doi.org/10.48550/arXiv.2405.10729'), ('doi', '10.48550/ARXIV.2405.10729'), ('eprinttype', 'arXiv'), ('eprint', '2405.10729'), ('timestamp', 'Sun, 06 Oct 2024 01:00:00 +0200'), ('biburl', 'https://dblp.org/rec/journals/corr/abs-2405-10729.bib'), ('bibsource', 'dblp computer science bibliography, https://dblp.org')])\n",
      "SUCESSFULLY PARSED DBLP:journals/corr/abs-2405-10729: \" Contestable {AI} needs Computational Argumentation  \"\n",
      "OrderedCaseInsensitiveDict([('title', 'Argumentative Causal Discovery'), ('journal', 'CoRR'), ('volume', 'abs/2405.11250'), ('year', '2024'), ('url', 'https://doi.org/10.48550/arXiv.2405.11250'), ('doi', '10.48550/ARXIV.2405.11250'), ('eprinttype', 'arXiv'), ('eprint', '2405.11250'), ('timestamp', 'Wed, 12 Jun 2024 01:00:00 +0200'), ('biburl', 'https://dblp.org/rec/journals/corr/abs-2405-11250.bib'), ('bibsource', 'dblp computer science bibliography, https://dblp.org')])\n",
      "SUCESSFULLY PARSED DBLP:journals/corr/abs-2405-11250: \" Argumentative Causal Discovery  \"\n",
      "OrderedCaseInsensitiveDict([('title', \"Explaining Classifiers' Outputs with Causal Models and Argumentation\"), ('journal', '{FLAP}'), ('volume', '10'), ('number', '3'), ('pages', '421--509'), ('year', '2023'), ('url', 'https://www.collegepublications.co.uk/downloads/ifcolog00059.pdf'), ('timestamp', 'Mon, 15 Jan 2024 00:00:00 +0100'), ('biburl', 'https://dblp.org/rec/journals/flap/00010ATB23.bib'), ('bibsource', 'dblp computer science bibliography, https://dblp.org')])\n",
      "SUCESSFULLY PARSED DBLP:journals/flap/00010ATB23: \" Explaining Classifiers' Outputs with Causal Models and Argum ... \"\n",
      "OrderedCaseInsensitiveDict([('title', 'Shapley-PC: Constraint-based Causal Structure Learning with Shapley Values'), ('journal', 'CoRR'), ('volume', 'abs/2312.11582'), ('year', '2023'), ('url', 'https://doi.org/10.48550/arXiv.2312.11582'), ('doi', '10.48550/ARXIV.2312.11582'), ('eprinttype', 'arXiv'), ('eprint', '2312.11582'), ('timestamp', 'Tue, 16 Jan 2024 00:00:00 +0100'), ('biburl', 'https://dblp.org/rec/journals/corr/abs-2312-11582.bib'), ('bibsource', 'dblp computer science bibliography, https://dblp.org')])\n",
      "SUCESSFULLY PARSED DBLP:journals/corr/abs-2312-11582: \" Shapley-PC: Constraint-based Causal Structure Learning with  ... \"\n",
      "OrderedCaseInsensitiveDict([('title', 'Causal Discovery and Injection for Feed-Forward Neural Networks'), ('journal', 'CoRR'), ('volume', 'abs/2205.09787'), ('year', '2022'), ('url', 'https://doi.org/10.48550/arXiv.2205.09787'), ('doi', '10.48550/ARXIV.2205.09787'), ('eprinttype', 'arXiv'), ('eprint', '2205.09787'), ('timestamp', 'Sat, 30 Sep 2023 01:00:00 +0200'), ('biburl', 'https://dblp.org/rec/journals/corr/abs-2205-09787.bib'), ('bibsource', 'dblp computer science bibliography, https://dblp.org')])\n",
      "SUCESSFULLY PARSED DBLP:journals/corr/abs-2205-09787: \" Causal Discovery and Injection for Feed-Forward Neural Netwo ... \"\n"
     ]
    }
   ],
   "source": [
    "for pubsource in publist:\n",
    "    parser = bibtex.Parser()\n",
    "    bibdata = parser.parse_file(publist[pubsource][\"file\"])\n",
    "\n",
    "    #loop through the individual references in a given bibtex file\n",
    "    for bib_id in bibdata.entries:\n",
    "        #reset default date\n",
    "        pub_year = \"1900\"\n",
    "        pub_month = \"01\"\n",
    "        pub_day = \"01\"\n",
    "        \n",
    "        b = bibdata.entries[bib_id].fields\n",
    "        print(b)\n",
    "        \n",
    "        try:\n",
    "            pub_year = f'{b[\"year\"]}'\n",
    "\n",
    "            #todo: this hack for month and day needs some cleanup\n",
    "            if \"month\" in b.keys(): \n",
    "                if(len(b[\"month\"])<3):\n",
    "                    pub_month = \"0\"+b[\"month\"]\n",
    "                    pub_month = pub_month[-2:]\n",
    "                elif(b[\"month\"] not in range(12)):\n",
    "                    tmnth = strptime(b[\"month\"][:3],'%b').tm_mon   \n",
    "                    pub_month = \"{:02d}\".format(tmnth) \n",
    "                else:\n",
    "                    pub_month = str(b[\"month\"])\n",
    "            if \"day\" in b.keys(): \n",
    "                pub_day = str(b[\"day\"])\n",
    "\n",
    "                \n",
    "            pub_date = pub_year+\"-\"+pub_month+\"-\"+pub_day\n",
    "            \n",
    "            #strip out {} as needed (some bibtex entries that maintain formatting)\n",
    "            clean_title = b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\" \",\"-\")    \n",
    "\n",
    "            url_slug = re.sub(\"\\\\[.*\\\\]|[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "            url_slug = url_slug.replace(\"--\",\"-\")\n",
    "\n",
    "            md_filename = (str(pub_date) + \"-\" + url_slug + publist[pubsource][\"venuekey\"] + \".md\").replace(\"--\",\"-\")\n",
    "            html_filename = (str(pub_date) + \"-\" + url_slug + publist[pubsource][\"venuekey\"]).replace(\"--\",\"-\")\n",
    "\n",
    "            #Build Citation from text\n",
    "            citation = \"\"\n",
    "\n",
    "            #citation authors - todo - add highlighting for primary author?\n",
    "            for author in bibdata.entries[bib_id].persons[\"author\"]:\n",
    "                citation = citation+\" \"+author.first_names[0]+\" \"+author.last_names[0]+\", \"\n",
    "\n",
    "            #citation title\n",
    "            citation = citation + \"\\\"\" + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + \".\\\"\"\n",
    "\n",
    "            #add venue logic depending on citation type\n",
    "            venue = publist[pubsource][\"venue-pretext\"]+b[publist[pubsource][\"venuekey\"]].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")\n",
    "\n",
    "            citation = citation + \" \" + html_escape(venue)\n",
    "            citation = citation + \", \" + pub_year + \".\"\n",
    "\n",
    "            \n",
    "            ## YAML variables\n",
    "            md = \"---\\ntitle: \\\"\"   + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + '\"\\n'\n",
    "            \n",
    "            md += \"\"\"collection: \"\"\" +  publist[pubsource][\"collection\"][\"name\"]\n",
    "\n",
    "            md += \"\"\"\\npermalink: \"\"\" + publist[pubsource][\"collection\"][\"permalink\"]  + html_filename\n",
    "            \n",
    "            note = False\n",
    "            if \"note\" in b.keys():\n",
    "                if len(str(b[\"note\"])) > 5:\n",
    "                    md += \"\\nexcerpt: '\" + html_escape(b[\"note\"]) + \"'\"\n",
    "                    note = True\n",
    "\n",
    "            md += \"\\ndate: \" + str(pub_date) \n",
    "\n",
    "            md += \"\\nvenue: '\" + html_escape(venue) + \"'\"\n",
    "            \n",
    "            url = False\n",
    "            if \"url\" in b.keys():\n",
    "                if len(str(b[\"url\"])) > 5:\n",
    "                    md += \"\\npaperurl: '\" + b[\"url\"] + \"'\"\n",
    "                    url = True\n",
    "\n",
    "            md += \"\\ncitation: '\" + html_escape(citation) + \"'\"\n",
    "\n",
    "            md += \"\\n---\"\n",
    "\n",
    "            \n",
    "            ## Markdown description for individual page\n",
    "            if note:\n",
    "                md += \"\\n\" + html_escape(b[\"note\"]) + \"\\n\"\n",
    "\n",
    "            if url:\n",
    "                md #+= \"\\n[Access paper here](\" + b[\"url\"] + \"){:target=\\\"_blank\\\"}\\n\" \n",
    "            else:\n",
    "                md += \"\\nUse [Google Scholar](https://scholar.google.com/scholar?q=\"+html.escape(clean_title.replace(\"-\",\"+\"))+\"){:target=\\\"_blank\\\"} for full citation\"\n",
    "\n",
    "            md_filename = os.path.basename(md_filename)\n",
    "\n",
    "            with open(\"../_publications/\" + md_filename, 'w') as f:\n",
    "                f.write(md)\n",
    "            print(f'SUCESSFULLY PARSED {bib_id}: \\\"', b[\"title\"][:60],\"...\"*(len(b['title'])>60),\"\\\"\")\n",
    "        # field may not exist for a reference\n",
    "        except KeyError as e:\n",
    "            print(f'WARNING Missing Expected Field {e} from entry {bib_id}: \\\"', b[\"title\"][:30],\"...\"*(len(b['title'])>30),\"\\\"\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
